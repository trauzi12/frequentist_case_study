{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequentist Inference Case Study - Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Part B of the Frequentist inference case study! The purpose of this case study is to help you apply the concepts associated with Frequentist inference in Python. In particular, you'll practice writing Python code to apply the following statistical concepts: \n",
    "* the _z_-statistic\n",
    "* the _t_-statistic\n",
    "* the difference and relationship between the two\n",
    "* the Central Limit Theorem, including its assumptions and consequences\n",
    "* how to estimate the population mean and standard deviation from a sample\n",
    "* the concept of a sampling distribution of a test statistic, particularly for the mean\n",
    "* how to combine these concepts to calculate a confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we used only data from a known normal distribution. **You'll now tackle real data, rather than simulated data, and answer some relevant real-world business problems using the data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hospital medical charges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that a hospital has hired you as their data scientist. An administrator is working on the hospital's business operations plan and needs you to help them answer some business questions. \n",
    "\n",
    "In this assignment notebook, you're going to use frequentist statistical inference on a data sample to answer the questions:\n",
    "* has the hospital's revenue stream fallen below a key threshold?\n",
    "* are patients with insurance really charged different amounts than those without?\n",
    "\n",
    "Answering that last question with a frequentist approach makes some assumptions, and requires some knowledge, about the two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use some data on medical charges obtained from [Kaggle](https://www.kaggle.com/easonlai/sample-insurance-claim-prediction-dataset). \n",
    "\n",
    "For the purposes of this exercise, assume the observations are the result of random sampling from our single hospital. Recall that in the previous assignment, we introduced the Central Limit Theorem (CLT), and its consequence that the distributions of sample statistics approach a normal distribution as $n$ increases. The amazing thing about this is that it applies to the sampling distributions of statistics that have been calculated from even highly non-normal distributions of data! Recall, also, that hypothesis testing is very much based on making inferences about such sample statistics. You're going to rely heavily on the CLT to apply frequentist (parametric) tests to answer the questions in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "from numpy.random import seed\n",
    "from scipy.stats import tests \n",
    "medical = pd.read_csv('insurance2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "      <th>insuranceclaim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex     bmi  children  smoker  region      charges  insuranceclaim\n",
       "0   19    0  27.900         0       1       3  16884.92400               1\n",
       "1   18    1  33.770         1       0       2   1725.55230               1\n",
       "2   28    1  33.000         3       0       2   4449.46200               0\n",
       "3   33    1  22.705         0       0       1  21984.47061               0\n",
       "4   32    1  28.880         0       0       1   3866.85520               1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q1:__ Plot the histogram of charges and calculate the mean and standard deviation. Comment on the appropriateness of these statistics for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ Since the charge data is extremely right skewed, the mean and standard deviation are strongly influenced by the outliers. Thus, the mean is higher than the true center of the data, and the spread will also be larger than the true spread of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(medical['charges'], bins=int(np.sqrt(medical.shape[0])), histtype='bar')\n",
    "plt.xlabel('hospital charges in dollars')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13270.422265141257, 12110.011236693994)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charges_mean=np.mean(medical['charges'])\n",
    "charges_std=np.std(medical['charges'], ddof=1)\n",
    "charges_mean, charges_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q2:__ The administrator is concerned that the actual average charge has fallen below 12,000, threatening the hospital's operational model. On the assumption that these data represent a random sample of charges, how would you justify that these data allow you to answer that question? And what would be the most appropriate frequentist test, of the ones discussed so far, to apply?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ Since the sample size is 1338, the CLT states that the sample means will be approximately normally distributed. Thus, we are able to conduct a t test to see if the average charges have fallen bellow 12, 000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q3:__ Given the nature of the administrator's concern, what is the appropriate confidence interval in this case? A ***one-sided*** or ***two-sided*** interval? (Refresh your understanding of this concept on p. 399 of the *AoS*). Calculate the critical value and the relevant 95% confidence interval for the mean, and comment on whether the administrator should be concerned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ Since we are only concered with determining if the charges have fallen below 12, 000, we can conduct a one-sided interval. In fact, it will be a left sided interval. The left sided interval is 12,725. Since the left sided confidence interval is larger than 12,000, the administrator should not be concerned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6459941145571324"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_critical=t.ppf(.05, len(medical['charges'])-1)\n",
    "t_critical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-544.9350813250253"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin_error=t_critical*charges_std/np.sqrt(len(medical['charges']))\n",
    "margin_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12725.48718381623"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charges_mean+margin_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The administrator then wants to know whether people with insurance really are charged a different amount to those without.\n",
    "\n",
    "__Q4:__ State the null and alternative hypothesis here. Use the _t_-test for the difference between means, where the pooled standard deviation of the two groups is given by:\n",
    "\\begin{equation}\n",
    "s_p = \\sqrt{\\frac{(n_0 - 1)s^2_0 + (n_1 - 1)s^2_1}{n_0 + n_1 - 2}}\n",
    "\\end{equation}\n",
    "\n",
    "and the *t*-test statistic is then given by:\n",
    "\n",
    "\\begin{equation}\n",
    "t = \\frac{\\bar{x}_0 - \\bar{x}_1}{s_p \\sqrt{1/n_0 + 1/n_1}}.\n",
    "\\end{equation}\n",
    "\n",
    "(If you need some reminding of the general definition of ***t-statistic***, check out the definition on p. 404 of *AoS*). \n",
    "\n",
    "What assumption about the variances of the two groups are we making here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ The null hypothesis is there is no difference between the average charges for people with insurance compared to those without. The pooled t test assumes the two groups have the same variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q5:__ Perform this hypothesis test both manually, using the above formulae, and then using the appropriate function from [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html#statistical-tests) (hint, you're looking for a function to perform a _t_-test on two independent samples). For the manual approach, calculate the value of the test statistic and then its probability (the p-value). Verify you get the same results from both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ How I calculated the t statistic, the alternative hypothesis is a left tailed test. The t stat is -11.89, which give a p-value approximately equal to 0. Thus, we reject the null hypothesis. Thus, there is sufficient evidence to suggest that on average patients with insurance are charged more than those without insurance. The p-values are not the same between the two methods because scipy.stats.ttest_ind_from_stats can only conduct a two tailed test. However, both the manual and the automated method provides the same t statistic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">charges</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insuranceclaim</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8821.421892</td>\n",
       "      <td>6446.510127</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16423.928277</td>\n",
       "      <td>14045.928419</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     charges                    \n",
       "                        mean           std count\n",
       "insuranceclaim                                  \n",
       "0                8821.421892   6446.510127   555\n",
       "1               16423.928277  14045.928419   783"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charge_insurance=medical.groupby('insuranceclaim').agg({'charges':['mean',\"std\", 'count']})\n",
    "charge_insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating summary statistics for the non-insurance claims\n",
    "std0=charge_insurance.loc[0,('charges',\"std\")]\n",
    "n0=charge_insurance.loc[0,('charges',\"count\")]\n",
    "mean0=charge_insurance.loc[0,('charges',\"mean\")]\n",
    "\n",
    "# calculating summary statistics for the insurance claims\n",
    "std1=charge_insurance.loc[1,('charges',\"std\")]\n",
    "n1=charge_insurance.loc[1,('charges',\"count\")]\n",
    "mean1=charge_insurance.loc[1,('charges',\"mean\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-11.89, 2.230615115810486e-31)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the pooled standard deviation\n",
    "sp=np.sqrt(((n0-1)*std0**2+(n1-1)*std1**2)/(n0+n1-2))\n",
    "\n",
    "# calculating the t stat\n",
    "t_stat=(mean0-mean1)/(sp*np.sqrt((1/n0)+(1/n1)))\n",
    "\n",
    "round(t_stat, 2), t.cdf(t_stat, (n0+n1-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function ttest_ind_from_stats in module scipy.stats.stats:\n",
      "\n",
      "ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var=True)\n",
      "    T-test for means of two independent samples from descriptive statistics.\n",
      "    \n",
      "    This is a two-sided test for the null hypothesis that two independent\n",
      "    samples have identical average (expected) values.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    mean1 : array_like\n",
      "        The mean(s) of sample 1.\n",
      "    std1 : array_like\n",
      "        The standard deviation(s) of sample 1.\n",
      "    nobs1 : array_like\n",
      "        The number(s) of observations of sample 1.\n",
      "    mean2 : array_like\n",
      "        The mean(s) of sample 2.\n",
      "    std2 : array_like\n",
      "        The standard deviations(s) of sample 2.\n",
      "    nobs2 : array_like\n",
      "        The number(s) of observations of sample 2.\n",
      "    equal_var : bool, optional\n",
      "        If True (default), perform a standard independent 2 sample test\n",
      "        that assumes equal population variances [1]_.\n",
      "        If False, perform Welch's t-test, which does not assume equal\n",
      "        population variance [2]_.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    statistic : float or array\n",
      "        The calculated t-statistics.\n",
      "    pvalue : float or array\n",
      "        The two-tailed p-value.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    scipy.stats.ttest_ind\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 0.16.0\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] https://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test\n",
      "    \n",
      "    .. [2] https://en.wikipedia.org/wiki/Welch%27s_t-test\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Suppose we have the summary data for two samples, as follows::\n",
      "    \n",
      "                         Sample   Sample\n",
      "                   Size   Mean   Variance\n",
      "        Sample 1    13    15.0     87.5\n",
      "        Sample 2    11    12.0     39.0\n",
      "    \n",
      "    Apply the t-test to this data (with the assumption that the population\n",
      "    variances are equal):\n",
      "    \n",
      "    >>> from scipy.stats import ttest_ind_from_stats\n",
      "    >>> ttest_ind_from_stats(mean1=15.0, std1=np.sqrt(87.5), nobs1=13,\n",
      "    ...                      mean2=12.0, std2=np.sqrt(39.0), nobs2=11)\n",
      "    Ttest_indResult(statistic=0.9051358093310269, pvalue=0.3751996797581487)\n",
      "    \n",
      "    For comparison, here is the data from which those summary statistics\n",
      "    were taken.  With this data, we can compute the same result using\n",
      "    `scipy.stats.ttest_ind`:\n",
      "    \n",
      "    >>> a = np.array([1, 3, 4, 6, 11, 13, 15, 19, 22, 24, 25, 26, 26])\n",
      "    >>> b = np.array([2, 4, 6, 9, 11, 13, 14, 15, 18, 19, 21])\n",
      "    >>> from scipy.stats import ttest_ind\n",
      "    >>> ttest_ind(a, b)\n",
      "    Ttest_indResult(statistic=0.905135809331027, pvalue=0.3751996797581486)\n",
      "    \n",
      "    Suppose we instead have binary data and would like to apply a t-test to\n",
      "    compare the proportion of 1s in two independent groups::\n",
      "    \n",
      "                          Number of    Sample     Sample\n",
      "                    Size    ones        Mean     Variance\n",
      "        Sample 1    150      30         0.2        0.16\n",
      "        Sample 2    200      45         0.225      0.174375\n",
      "    \n",
      "    The sample mean :math:`\\hat{p}` is the proportion of ones in the sample\n",
      "    and the variance for a binary observation is estimated by\n",
      "    :math:`\\hat{p}(1-\\hat{p})`.\n",
      "    \n",
      "    >>> ttest_ind_from_stats(mean1=0.2, std1=np.sqrt(0.16), nobs1=150,\n",
      "    ...                      mean2=0.225, std2=np.sqrt(0.17437), nobs2=200)\n",
      "    Ttest_indResult(statistic=-0.564327545549774, pvalue=0.5728947691244874)\n",
      "    \n",
      "    For comparison, we could compute the t statistic and p-value using\n",
      "    arrays of 0s and 1s and `scipy.stat.ttest_ind`, as above.\n",
      "    \n",
      "    >>> group1 = np.array([1]*30 + [0]*(150-30))\n",
      "    >>> group2 = np.array([1]*45 + [0]*(200-45))\n",
      "    >>> ttest_ind(group1, group2)\n",
      "    Ttest_indResult(statistic=-0.5627179589855622, pvalue=0.573989277115258)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scipy.stats.ttest_ind_from_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-11.893299030876712, pvalue=4.461230231620717e-31)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.ttest_ind_from_stats(mean0, std0, n0, mean1, std1, n1, equal_var=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Hopefully you got the exact same numerical results. This shows that you correctly calculated the numbers by hand. Secondly, you used the correct function and saw that it's much easier to use. All you need to do is pass your data to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q6:__ Conceptual question: look through the documentation for statistical test functions in scipy.stats. You'll see the above _t_-test for a sample, but can you see an equivalent one for performing a *z*-test from a sample? Comment on your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function ttest_1samp in module scipy.stats.stats:\n",
      "\n",
      "ttest_1samp(a, popmean, axis=0, nan_policy='propagate')\n",
      "    Calculate the T-test for the mean of ONE group of scores.\n",
      "    \n",
      "    This is a two-sided test for the null hypothesis that the expected value\n",
      "    (mean) of a sample of independent observations `a` is equal to the given\n",
      "    population mean, `popmean`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Sample observation.\n",
      "    popmean : float or array_like\n",
      "        Expected value in null hypothesis. If array_like, then it must have the\n",
      "        same shape as `a` excluding the axis dimension.\n",
      "    axis : int or None, optional\n",
      "        Axis along which to compute test. If None, compute over the whole\n",
      "        array `a`.\n",
      "    nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "        Defines how to handle when input contains nan.\n",
      "        The following options are available (default is 'propagate'):\n",
      "    \n",
      "          * 'propagate': returns nan\n",
      "          * 'raise': throws an error\n",
      "          * 'omit': performs the calculations ignoring nan values\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    statistic : float or array\n",
      "        t-statistic.\n",
      "    pvalue : float or array\n",
      "        Two-sided p-value.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy import stats\n",
      "    \n",
      "    >>> np.random.seed(7654567)  # fix seed to get the same result\n",
      "    >>> rvs = stats.norm.rvs(loc=5, scale=10, size=(50,2))\n",
      "    \n",
      "    Test if mean of random sample is equal to true mean, and different mean.\n",
      "    We reject the null hypothesis in the second case and don't reject it in\n",
      "    the first case.\n",
      "    \n",
      "    >>> stats.ttest_1samp(rvs,5.0)\n",
      "    (array([-0.68014479, -0.04323899]), array([ 0.49961383,  0.96568674]))\n",
      "    >>> stats.ttest_1samp(rvs,0.0)\n",
      "    (array([ 2.77025808,  4.11038784]), array([ 0.00789095,  0.00014999]))\n",
      "    \n",
      "    Examples using axis and non-scalar dimension for population mean.\n",
      "    \n",
      "    >>> stats.ttest_1samp(rvs,[5.0,0.0])\n",
      "    (array([-0.68014479,  4.11038784]), array([  4.99613833e-01,   1.49986458e-04]))\n",
      "    >>> stats.ttest_1samp(rvs.T,[5.0,0.0],axis=1)\n",
      "    (array([-0.68014479,  4.11038784]), array([  4.99613833e-01,   1.49986458e-04]))\n",
      "    >>> stats.ttest_1samp(rvs,[[5.0],[0.0]])\n",
      "    (array([[-0.68014479, -0.04323899],\n",
      "           [ 2.77025808,  4.11038784]]), array([[  4.99613833e-01,   9.65686743e-01],\n",
      "           [  7.89094663e-03,   1.49986458e-04]]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scipy.stats.ttest_1samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ The is not an equivalent version for the z test. However, if you have a large enough sample size, the t distribution converges to the standard normal; thus, you can approxiamte the z test from the t test when the sample size is sufficiently large. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having completed this project notebook, you now have good hands-on experience:\n",
    "* using the central limit theorem to help you apply frequentist techniques to answer questions that pertain to very non-normally distributed data from the real world\n",
    "* performing inference using such data to answer business questions\n",
    "* forming a hypothesis and framing the null and alternative hypotheses\n",
    "* testing this using a _t_-test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
